{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T04:52:38.978438Z",
     "start_time": "2018-03-30T04:52:38.912595Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams['font.family'] = 'serif'\n",
    "rcParams['font.serif'] = 'times new roman'\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the data, which contains one row per song so that it instead contains one row per unique word per song, with all other attributes of the song duplicated for all unique words in the song. Furthermore, each unique word will have a count of its frequency for that song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T04:52:41.324666Z",
     "start_time": "2018-03-30T04:52:41.303757Z"
    },
    "collapsed": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def row_to_df(x):\n",
    "    if not isinstance(x['lyrics'], str):\n",
    "        return None\n",
    "    else:\n",
    "        nonlyrics = x.drop('lyrics')\n",
    "        lyrics = pd.Series(x.lyrics.split()).value_counts()\n",
    "        lyrics = pd.DataFrame(lyrics).reset_index()\n",
    "        lyrics.columns = ['word', 'count']\n",
    "        lyrics['dummy'] = 1\n",
    "        nonlyrics['dummy'] = 1\n",
    "        nonlyrics = pd.DataFrame(nonlyrics).T\n",
    "        return pd.merge(nonlyrics, lyrics, how='right', on='dummy')\n",
    "\n",
    "def tidy_df(df):\n",
    "    df_list = list()\n",
    "    for index, row in df.iterrows():\n",
    "        song_df = row_to_df(row)\n",
    "        df_list.append(song_df)\n",
    "    return pd.concat(df_list, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a few more song-level attributes before tranforming dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T04:53:05.894048Z",
     "start_time": "2018-03-30T04:53:05.613504Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/billboard-spotify.csv', encoding='latin1')\n",
    "\n",
    "\n",
    "\n",
    "# word count of song lyrics\n",
    "count_words = lambda x: len(x.split()) if isinstance(x, str) else 0\n",
    "df['num_words'] = df['lyrics'].apply(count_words)\n",
    "\n",
    "# number of words per second\n",
    "df['words_per_sec'] = df['num_words'] / (df['duration_ms'] / 1000)\n",
    "\n",
    "# song duration in minutes\n",
    "df['duration_min'] = df['duration_ms'] / 1000 / 60\n",
    "\n",
    "# the primary artist (removes featured artists)\n",
    "df['artist_base'] = df['artist'].apply(lambda x: re.sub(\"\\s\\(*feat.*\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T04:53:34.169148Z",
     "start_time": "2018-03-30T04:53:08.427724Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tidy_words = tidy_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only words that appear in at least 10 songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T05:22:15.368481Z",
     "start_time": "2018-03-30T05:22:12.034322Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "songs_per_word = df_tidy_words.groupby('word')['song'].agg(pd.Series.nunique)\n",
    "songs_per_word = songs_per_word[songs_per_word >= 10]\n",
    "words_to_keep = list(songs_per_word.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T05:22:39.152750Z",
     "start_time": "2018-03-30T05:22:18.036067Z"
    }
   },
   "outputs": [],
   "source": [
    "mask = df_tidy_words['word'].apply(lambda x: x in words_to_keep)\n",
    "df_tidy_words_filtered = df_tidy_words.loc[mask,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T05:22:48.110199Z",
     "start_time": "2018-03-30T05:22:41.229260Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tidy_words_filtered.to_csv('../data/tidy-words.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-3.6",
   "language": "python",
   "name": "python-3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
